{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path= \"data\"\n",
    "signal_name = 'signal1'\n",
    "normal_files = glob.glob(data_path+'/'+signal_name+'/normal/'+\"*99.csv\")\n",
    "anormal_drift_files = glob.glob(data_path+'/'+signal_name+'/anormal_drift/'+\"*99.csv\")\n",
    "anormal_erratic_files = glob.glob(data_path+'/'+signal_name+'/anormal_erratic/'+\"*99.csv\")\n",
    "anormal_hardover_files = glob.glob(data_path+'/'+signal_name+'/anormal_hardover/'+\"*99.csv\")\n",
    "anormal_spike_files = glob.glob(data_path+'/'+signal_name+'/anormal_spike/'+\"*99.csv\")\n",
    "anormal_stuck_files = glob.glob(data_path+'/'+signal_name+'/anormal_stuck/'+\"*99.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/signal1/anormal_drift\\\\signal1_drift99.csv']\n"
     ]
    }
   ],
   "source": [
    "print(anormal_drift_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataReader(path_names):\n",
    "    data_n = pd.DataFrame() #판다스의 데이터프레임 형태로 프레임 생성\n",
    "    for i in path_names:\n",
    "        low_data = pd.read_csv(i)# 판다스 형태로 읽음, 한csv파일씩 읽기 떄문에 다음 라인에서 하나로 합침\n",
    "        data_n = pd.concat([data_n,low_data],ignore_index=True)\n",
    "    return data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_datas = dataReader(normal_files)\n",
    "drift_datas = dataReader(anormal_drift_files)\n",
    "hardover_datas = dataReader(anormal_hardover_files)\n",
    "erratic_datas = dataReader(anormal_erratic_files)\n",
    "spike_datas = dataReader(anormal_spike_files)\n",
    "stuck_datas = dataReader(anormal_stuck_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([drift_datas,hardover_datas,erratic_datas,spike_datas,stuck_datas],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data)):\n",
    "    if( all_data['error'][i] != 0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data shape 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력, 출력값 크기 설정\n",
    "n_time_in = 16 # 개의 데이터 입력으로 받음\n",
    "ntime_out = 1 # 다음 한개의 데이터 목표값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM, LSTM-AE softmax\n",
    "def X_to_XyLSTM_softmax(data_pd,ntime_in,ntime_out):#X변형할 시계열 데이터 n_time_in 만큼 하나의 input으로 봄, ntime_out만큼 뒤에꺼를 예측\n",
    "    nsample = len(data_pd) - ntime_in -ntime_out + 1\n",
    "    X_ntime = [0 for _ in range(nsample)]\n",
    "    for i in range(nsample):\n",
    "        X_ntime[i] = data_pd['value'][i:i+ntime_in]\n",
    "    X_train = np.reshape(X_ntime,(nsample,ntime_in,1))#2차원 배열을 3차원 배열으로\n",
    "    #print('X',X_train.shape)\n",
    "    y_nfuture = [0 for _ in range(nsample)]\n",
    "    for i in range(nsample):\n",
    "        y_nfuture[i] = data_pd['error'][i+ntime_in:i+ntime_in+ntime_out]\n",
    "    y_train = np.array(y_nfuture)\n",
    "    #print('y',y_train.shape)\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LSTM_train, y_LSTM_train = X_to_XyLSTM_softmax(all_data,n_time_in,ntime_out)\n",
    "\n",
    "new_y = []\n",
    "for i in range(len(y_LSTM_train)):\n",
    "    if y_LSTM_train[i] == 0:\n",
    "        new_y.append([1,0,0,0,0,0])\n",
    "    if y_LSTM_train[i] == 1:\n",
    "        new_y.append([0,1,0,0,0,0])\n",
    "    if y_LSTM_train[i] == 2:\n",
    "        new_y.append([0,0,1,0,0,0])\n",
    "    if y_LSTM_train[i] == 3:\n",
    "        new_y.append([0,0,0,1,0,0])\n",
    "    if y_LSTM_train[i] == 4:\n",
    "        new_y.append([0,0,0,0,1,0])\n",
    "    if y_LSTM_train[i] == 5:\n",
    "        new_y.append([0,0,0,0,0,1])\n",
    "y_LSTM_train = np.array(new_y)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20144, 16, 1)\n",
      "(20144, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_LSTM_train.shape)\n",
    "print(y_LSTM_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your dataset (X represents your features, y represents your target variable)\n",
    "X, y = X_LSTM_train, y_LSTM_train\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test in this example)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#AE\\ndef X_to_XyAE_shape(X,ntime_out): #X변형할 시계열 데이터, ntime_out만큼 뒤에꺼를 예측\\n    nsample = len(X) - ntime_out\\n    X_train = np.array(X[:nsample])\\n    y_train = np.array(X[ntime_out:len(X)])\\n    #print('X',X_train.shape)\\n    #print('y',y_train.shape)\\n    return X_train,y_train\\n\\nn_time_in = 32 # 10개의 데이터 입력으로 받음\\nntime_out = 1 # 다음 한개의 데이터 목표값\\nX_AE_train, y_AE_train = X_to_XyAE_shape(normal_datas['value'],ntime_out)\\n\\n\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#AE\n",
    "def X_to_XyAE_shape(X,ntime_out): #X변형할 시계열 데이터, ntime_out만큼 뒤에꺼를 예측\n",
    "    nsample = len(X) - ntime_out\n",
    "    X_train = np.array(X[:nsample])\n",
    "    y_train = np.array(X[ntime_out:len(X)])\n",
    "    #print('X',X_train.shape)\n",
    "    #print('y',y_train.shape)\n",
    "    return X_train,y_train\n",
    "\n",
    "n_time_in = 32 # 10개의 데이터 입력으로 받음\n",
    "ntime_out = 1 # 다음 한개의 데이터 목표값\n",
    "X_AE_train, y_AE_train = X_to_XyAE_shape(normal_datas['value'],ntime_out)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#AE 모델\\nAE_model = Sequential()\\n\\nAE_model.add(InputLayer(input_shape=(1,1)))\\nAE_model.add(Dense(128, activation=\\'relu\\',kernel_initializer=\\'random_uniform\\'))\\nAE_model.add(Dense(64, activation=\\'relu\\',kernel_initializer=\\'random_uniform\\'))\\nAE_model.add(Dense(32, activation=\\'relu\\',kernel_initializer=\\'random_uniform\\'))\\nAE_model.add(Dense(64, activation=\\'relu\\',kernel_initializer=\\'random_uniform\\'))\\nAE_model.add(Dense(128, activation=\\'relu\\',kernel_initializer=\\'random_uniform\\'))\\nAE_model.add(Dense(ntime_out,activation=\\'linear\\'))\\n\\nAE_model.compile(loss=\"mean_squared_error\",optimizer=\\'adam\\')\\n'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import InputLayer, Dense, LSTM\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "#LSTM_AE 모델\n",
    "LSTM_AE_model = Sequential()\n",
    "\n",
    "LSTM_AE_model.add(LSTM(128, input_shape=(n_time_in, 1)))\n",
    "LSTM_AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "LSTM_AE_model.add(Dense(6,activation = 'softmax'))\n",
    "\n",
    "LSTM_AE_model.compile(loss=\"categorical_crossentropy\",optimizer='adam')\n",
    "\n",
    "#LSTM 모델\n",
    "LSTM_model = Sequential()\n",
    "\n",
    "LSTM_model.add(LSTM(128, input_shape=(n_time_in, 1)))\n",
    "LSTM_model.add(Dense(6,activation = 'softmax')) # error 의 label 이 총 6개 이므로\n",
    "\n",
    "LSTM_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "\"\"\"\n",
    "#AE 모델\n",
    "AE_model = Sequential()\n",
    "\n",
    "AE_model.add(InputLayer(input_shape=(1,1)))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(32, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(64, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(128, activation='relu',kernel_initializer='random_uniform'))\n",
    "AE_model.add(Dense(ntime_out,activation='linear'))\n",
    "\n",
    "AE_model.compile(loss=\"mean_squared_error\",optimizer='adam')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM_AE_model.fit(X_LSTM_train, y_LSTM_train, epochs=1, batch_size=100, verbose=0)\n",
    "history=LSTM_model.fit(X_train,y_train, epochs=1, batch_size=100, verbose=0)\n",
    "#AE_model.fit(X_AE_train,y_AE_train, epochs=1, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4029\n",
      "4029\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = LSTM_model.predict(X_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1]\n",
      "[2.5146406e-03 9.7405842e-05 2.4283314e-04 5.0799747e-04 2.6096407e-04\n",
      " 9.9637622e-01]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])\n",
    "print(y_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predict = []\n",
    "for data1 in range(len(y_predict)):\n",
    "    predict_01 = [0 for i in range(6)]\n",
    "    max_index = np.argmax(y_predict[data1])\n",
    "    predict_01[max_index] = 1\n",
    "    total_predict.append(predict_01)\n",
    "total_predict = np.array(total_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1]\n",
      "[0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])\n",
    "print(total_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "16\n",
      "19\n",
      "24\n",
      "31\n",
      "47\n",
      "69\n",
      "83\n",
      "106\n",
      "113\n",
      "120\n",
      "126\n",
      "131\n",
      "151\n",
      "164\n",
      "178\n",
      "195\n",
      "199\n",
      "219\n",
      "229\n",
      "233\n",
      "237\n",
      "242\n",
      "293\n",
      "298\n",
      "303\n",
      "309\n",
      "342\n",
      "349\n",
      "350\n",
      "353\n",
      "371\n",
      "375\n",
      "379\n",
      "387\n",
      "392\n",
      "404\n",
      "405\n",
      "413\n",
      "419\n",
      "428\n",
      "438\n",
      "449\n",
      "479\n",
      "485\n",
      "498\n",
      "543\n",
      "548\n",
      "576\n",
      "578\n",
      "584\n",
      "592\n",
      "651\n",
      "657\n",
      "668\n",
      "709\n",
      "714\n",
      "715\n",
      "719\n",
      "726\n",
      "728\n",
      "744\n",
      "761\n",
      "781\n",
      "786\n",
      "804\n",
      "806\n",
      "810\n",
      "823\n",
      "838\n",
      "847\n",
      "848\n",
      "850\n",
      "855\n",
      "873\n",
      "894\n",
      "913\n",
      "924\n",
      "957\n",
      "996\n",
      "1011\n",
      "1012\n",
      "1019\n",
      "1027\n",
      "1033\n",
      "1045\n",
      "1048\n",
      "1050\n",
      "1101\n",
      "1123\n",
      "1125\n",
      "1132\n",
      "1154\n",
      "1156\n",
      "1168\n",
      "1175\n",
      "1207\n",
      "1229\n",
      "1257\n",
      "1272\n",
      "1282\n",
      "1304\n",
      "1311\n",
      "1338\n",
      "1344\n",
      "1359\n",
      "1361\n",
      "1381\n",
      "1383\n",
      "1395\n",
      "1434\n",
      "1437\n",
      "1443\n",
      "1456\n",
      "1475\n",
      "1478\n",
      "1479\n",
      "1483\n",
      "1488\n",
      "1491\n",
      "1505\n",
      "1508\n",
      "1509\n",
      "1536\n",
      "1541\n",
      "1551\n",
      "1558\n",
      "1571\n",
      "1573\n",
      "1580\n",
      "1595\n",
      "1605\n",
      "1635\n",
      "1637\n",
      "1639\n",
      "1646\n",
      "1652\n",
      "1656\n",
      "1673\n",
      "1685\n",
      "1688\n",
      "1711\n",
      "1712\n",
      "1721\n",
      "1722\n",
      "1730\n",
      "1738\n",
      "1755\n",
      "1761\n",
      "1763\n",
      "1776\n",
      "1784\n",
      "1801\n",
      "1840\n",
      "1849\n",
      "1855\n",
      "1872\n",
      "1874\n",
      "1884\n",
      "1892\n",
      "1896\n",
      "1915\n",
      "1921\n",
      "1927\n",
      "1935\n",
      "1942\n",
      "1943\n",
      "1945\n",
      "1972\n",
      "1973\n",
      "1998\n",
      "2013\n",
      "2018\n",
      "2051\n",
      "2052\n",
      "2106\n",
      "2127\n",
      "2133\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2155\n",
      "2188\n",
      "2195\n",
      "2211\n",
      "2254\n",
      "2280\n",
      "2311\n",
      "2327\n",
      "2329\n",
      "2331\n",
      "2334\n",
      "2356\n",
      "2361\n",
      "2455\n",
      "2511\n",
      "2513\n",
      "2519\n",
      "2546\n",
      "2568\n",
      "2579\n",
      "2597\n",
      "2604\n",
      "2614\n",
      "2617\n",
      "2628\n",
      "2638\n",
      "2666\n",
      "2679\n",
      "2682\n",
      "2717\n",
      "2724\n",
      "2750\n",
      "2766\n",
      "2830\n",
      "2855\n",
      "2863\n",
      "2877\n",
      "2879\n",
      "2882\n",
      "2899\n",
      "2906\n",
      "2919\n",
      "2971\n",
      "2977\n",
      "2985\n",
      "2994\n",
      "3029\n",
      "3042\n",
      "3055\n",
      "3086\n",
      "3093\n",
      "3101\n",
      "3143\n",
      "3169\n",
      "3196\n",
      "3209\n",
      "3214\n",
      "3226\n",
      "3238\n",
      "3262\n",
      "3265\n",
      "3267\n",
      "3281\n",
      "3291\n",
      "3294\n",
      "3318\n",
      "3334\n",
      "3337\n",
      "3340\n",
      "3345\n",
      "3350\n",
      "3359\n",
      "3362\n",
      "3367\n",
      "3412\n",
      "3438\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3456\n",
      "3483\n",
      "3513\n",
      "3527\n",
      "3531\n",
      "3536\n",
      "3539\n",
      "3544\n",
      "3563\n",
      "3574\n",
      "3577\n",
      "3591\n",
      "3593\n",
      "3599\n",
      "3610\n",
      "3616\n",
      "3618\n",
      "3632\n",
      "3638\n",
      "3653\n",
      "3670\n",
      "3698\n",
      "3717\n",
      "3730\n",
      "3735\n",
      "3737\n",
      "3738\n",
      "3745\n",
      "3771\n",
      "3773\n",
      "3774\n",
      "3779\n",
      "3788\n",
      "3802\n",
      "3807\n",
      "3812\n",
      "3814\n",
      "3820\n",
      "3838\n",
      "3854\n",
      "3866\n",
      "3870\n",
      "3881\n",
      "3882\n",
      "3887\n",
      "3903\n",
      "3908\n",
      "3922\n",
      "3928\n",
      "3929\n",
      "3956\n",
      "3965\n",
      "3969\n",
      "3971\n",
      "3989\n",
      "4016\n",
      "4021\n",
      "cnt 317\n",
      "4029\n",
      "0.9213204269049392\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(y_test)):\n",
    "    result = np.array_equal(y_test[i], total_predict[i]) \n",
    "    if(result == False):\n",
    "        print(i)\n",
    "        cnt += 1\n",
    "\n",
    "print(\"cnt\",cnt)\n",
    "print(len(y_test))\n",
    "\n",
    "print((len(y_test)-cnt)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_matrix(total_predict,y_test):\n",
    "    predict_size = len(total_predict)\n",
    "    #오차행렬 초기화\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0 \n",
    "    Accuracy = np.nan\n",
    "    Recall = np.nan\n",
    "    Percision = np.nan\n",
    "    Specificity = np.nan\n",
    "    for i in range(predict_size):\n",
    "        modelP = 0\n",
    "        modelN = 0\n",
    "        trueP = 0\n",
    "        trueN = 0\n",
    "        # 모델에 대한 P,N\n",
    "        equl =np.array_equal(total_predict[i],np.array([1,0,0,0,0,0]))\n",
    "        if(equl==True): # 에러가 아니면\n",
    "            modelN = 1\n",
    "        else:\n",
    "            modelP = 1\n",
    "        #실제값에 대한 P,N\n",
    "        equl =np.array_equal(y_test[i],np.array([1,0,0,0,0,0]))\n",
    "        if(equl == True):\n",
    "            trueN = 1\n",
    "        else:\n",
    "            trueP = 1\n",
    "        #오차 행렬 업데이트\n",
    "        if(modelP==1 and trueP == 1):\n",
    "            tp += 1\n",
    "        elif(modelP == 1 and trueN == 1):\n",
    "            fp += 1\n",
    "        elif(modelN == 1 and trueN == 1):\n",
    "            tn += 1\n",
    "        elif(modelN == 1 and trueP == 1):\n",
    "            fn += 1\n",
    "    if(tp+tn+fp+fn != 0):\n",
    "        Accuracy = float(tp+tn)/float(tp+tn+fp+fn) # 전체 예측 중 맞게 예측\n",
    "    if(tp+fn != 0):\n",
    "        Recall = float(tp)/float(tp+fn) # 실제 오류 중 오류라고 예측한 것\n",
    "    if(tp+fp != 0):\n",
    "        Percision = float(tp)/float(tp+fp) # 오류라고 예측한 것 중 실제 오류\n",
    "    if(fp+tn != 0):\n",
    "        Specificity = float(tn)/float(fp+tn) # 오류가 아니라고 예측 한 것 중 정말 오류가 아닌 것\n",
    "    \n",
    "    return Accuracy,Recall,Percision,Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy,Recall,Percision,Specificity=error_matrix(total_predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_time_in 16\n",
      "=======================\n",
      "Accuracy 95.66\n",
      "Recall 80.49\n",
      "Percision 99.86\n",
      "\n",
      "\n",
      "Specificity 99.97\n"
     ]
    }
   ],
   "source": [
    "print(\"n_time_in\",n_time_in)\n",
    "print(\"=======================\")\n",
    "print(\"Accuracy\",round(Accuracy*100,2))\n",
    "print(\"Recall\",round(Recall*100,2))\n",
    "print(\"Percision\",round(Percision*100,2))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Specificity\",round(Specificity*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9213 - precision_1: 0.9246 - recall_1: 0.8178\n",
      "\n",
      "n_time_in 16\n",
      "=======================\n",
      "Accuracy 92.13\n",
      "Recall 81.78\n",
      "Percision 99.86\n"
     ]
    }
   ],
   "source": [
    "loss,Accuracy,Precision,Recall = LSTM_model.evaluate(X_test, y_test)\n",
    "#print(loss)\n",
    "print(\"\\nn_time_in\",n_time_in)\n",
    "print(\"=======================\")\n",
    "print(\"Accuracy\",round(Accuracy*100,2))\n",
    "print(\"Recall\",round(Recall*100,2))\n",
    "print(\"Percision\",round(Percision*100,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
